# ä»£ç ä¿®å¤å»ºè®® - è¯¦ç»†å®æ–½æ–¹æ¡ˆ

## ä¼˜å…ˆçº§1ï¼ˆç«‹å³ä¿®å¤ï¼‰

### ä¿®å¤1.1ï¼šscperturb_dataset.py éšæœºç§å­å›ºå®šé—®é¢˜

**æ–‡ä»¶**ï¼š`src/data/scperturb_dataset.py`
**è¡Œå·**ï¼š202-204
**ä¸¥é‡æ€§**ï¼šğŸ”´ é«˜ï¼ˆå½±å“æ•°æ®é›†æœ‰æ•ˆæ€§ï¼‰
**ä¿®å¤æ—¶é—´**ï¼š5åˆ†é’Ÿ

**é—®é¢˜æè¿°**ï¼š
```python
# å½“å‰ä»£ç 
rng = np.random.RandomState(42)  # âŒ å›ºå®šç§å­
t0_sampled = rng.choice(t0_indices, size=n_pairs, replace=True)
t1_sampled = rng.choice(t1_indices, size=n_pairs, replace=True)
```

**é—®é¢˜å½±å“**ï¼š
- æ¯æ¬¡è¿è¡Œç”Ÿæˆå®Œå…¨ç›¸åŒçš„æ•°æ®å¯¹
- train/val/testæ— æ³•çœŸæ­£åˆ†å‰²
- äº¤å‰éªŒè¯å¤±æ•ˆ

**ä¿®å¤æ–¹æ¡ˆ**ï¼š

```python
def __init__(
    self,
    adata,
    cond_encoder: ConditionEncoder,
    tissue2idx: Dict[str, int],
    max_pairs_per_condition: int = 500,
    seed: Optional[int] = None  # æ–°å¢å‚æ•°
):
    self.adata = adata
    self.cond_encoder = cond_encoder
    self.tissue2idx = tissue2idx
    self.n_tissues = len(tissue2idx)
    self.max_pairs_per_condition = max_pairs_per_condition
    self.seed = seed  # ä¿å­˜seedç”¨äºreproducibility

    # æ„å»ºé…å¯¹
    self.pairs = self._build_pairs()

def _build_pairs(self) -> List[Tuple[int, int, Dict]]:
    """æ„å»ºç»†èƒé…å¯¹åˆ—è¡¨"""
    pairs = []

    # ... ä¹‹å‰çš„ä»£ç  ...

    for condition, group in grouped:
        # åˆ†ç¦»t0å’Œt1
        t0_indices = group[group["timepoint"] == "t0"].index.tolist()
        t1_indices = group[group["timepoint"] == "t1"].index.tolist()

        if len(t0_indices) == 0 or len(t1_indices) == 0:
            continue

        # é‡‡æ ·é…å¯¹
        n_pairs = min(
            len(t0_indices),
            len(t1_indices),
            self.max_pairs_per_condition
        )

        # âœ“ ä¿®å¤ï¼šä½¿ç”¨å¯æ§çš„éšæœºç§å­
        rng = np.random.RandomState(self.seed)
        t0_sampled = rng.choice(t0_indices, size=n_pairs, replace=True)
        t1_sampled = rng.choice(t1_indices, size=n_pairs, replace=True)

        # ... åç»­ä»£ç  ...

    return pairs
```

**ä½¿ç”¨ç¤ºä¾‹**ï¼š
```python
# è®­ç»ƒé›†ï¼šéšæœºé‡‡æ ·ï¼ˆseed=Noneï¼‰
train_dataset = SCPerturbPairDataset(adata, cond_encoder, tissue2idx, seed=None)

# éªŒè¯é›†ï¼šä½¿ç”¨å›ºå®šseedä¿è¯å¯é‡å¤æ€§
val_dataset = SCPerturbPairDataset(adata, cond_encoder, tissue2idx, seed=42)

# æµ‹è¯•é›†ï¼šä½¿ç”¨ä¸åŒseed
test_dataset = SCPerturbPairDataset(adata, cond_encoder, tissue2idx, seed=123)
```

---

### ä¿®å¤1.2ï¼šoperator.py power iterationæ¢¯åº¦é—®é¢˜

**æ–‡ä»¶**ï¼š`src/models/operator.py`
**è¡Œå·**ï¼š399-406ï¼ˆcompute_operator_normæ–¹æ³•ï¼‰
**ä¸¥é‡æ€§**ï¼šğŸ”´ é«˜ï¼ˆå¯èƒ½å¯¼è‡´æ¢¯åº¦å¼‚å¸¸ï¼‰
**ä¿®å¤æ—¶é—´**ï¼š5åˆ†é’Ÿ

**é—®é¢˜æè¿°**ï¼š
```python
# å½“å‰ä»£ç 
for i in range(B):
    v = torch.randn(self.latent_dim, device=A_theta.device)
    for _ in range(5):
        v = A_theta[i] @ v  # âŒ vä¼šç§¯ç´¯æ¢¯åº¦
        v = v / (v.norm() + 1e-8)
    norms[i] = (v @ (A_theta[i] @ v)).abs()
```

**é—®é¢˜å½±å“**ï¼š
- power iterationä¸åº”è®¡ç®—æ¢¯åº¦ï¼ˆèŒƒæ•°æ˜¯è¾…åŠ©è®¡ç®—ï¼‰
- å¯èƒ½å¯¼è‡´æ¢¯åº¦å›¾è¿‡æ·±
- åå‘ä¼ æ’­å˜æ…¢

**ä¿®å¤æ–¹æ¡ˆ**ï¼š

```python
def compute_operator_norm(
    self,
    tissue_idx: torch.Tensor,
    cond_vec: torch.Tensor,
    norm_type: str = "spectral"
) -> torch.Tensor:
    """
    è®¡ç®—ç®—å­A_Î¸çš„èŒƒæ•°ï¼ˆç”¨äºç›‘æ§ç¨³å®šæ€§ï¼‰

    ... docstring ...
    """
    # æ„é€ è™šæ‹Ÿè¾“å…¥ï¼ˆä¸å®é™…ä½¿ç”¨zï¼‰
    B = tissue_idx.size(0)
    z_dummy = torch.zeros(B, self.latent_dim, device=tissue_idx.device)

    # è·å–A_Î¸
    _, A_theta, _ = self.forward(z_dummy, tissue_idx, cond_vec)  # (B, d, d)

    if norm_type == "frobenius":
        # FrobeniusèŒƒæ•°ï¼š||A||_F = sqrt(Î£áµ¢â±¼ AÂ²áµ¢â±¼)
        norms = torch.norm(A_theta.view(B, -1), dim=-1)  # (B,)
    elif norm_type == "spectral":
        # è°±èŒƒæ•°ï¼šä½¿ç”¨power iterationè¿‘ä¼¼
        norms = torch.zeros(B, device=A_theta.device)
        with torch.no_grad():  # âœ“ ä¿®å¤ï¼špower iterationä¸éœ€è¦æ¢¯åº¦
            for i in range(B):
                v = torch.randn(self.latent_dim, device=A_theta.device)
                for _ in range(5):
                    v = A_theta[i] @ v
                    v = v / (v.norm() + 1e-8)
                norms[i] = (v @ (A_theta[i] @ v)).abs()
    else:
        raise ValueError(f"Unknown norm_type: {norm_type}")

    return norms
```

**ç±»ä¼¼ä¿®å¤**ï¼šspectral_penaltyæ–¹æ³•ï¼ˆç¬¬223-309è¡Œï¼‰ä¹Ÿéœ€è¦ä¿®å¤ï¼š

```python
def spectral_penalty(
    self,
    max_allowed: float = 1.05,
    n_iterations: int = 5
) -> torch.Tensor:
    """è®¡ç®—è°±èŒƒæ•°ç¨³å®šæ€§æ­£åˆ™åŒ–é¡¹"""
    penalty = torch.tensor(0.0, device=self.A0_tissue.device)

    # å¯¹æ¯ä¸ªç»„ç»‡çš„åŸºçº¿ç®—å­ A_t^(0) è®¡ç®—è°±èŒƒæ•°
    for t in range(self.n_tissues):
        A0 = self.A0_tissue[t]  # (d, d)

        # âœ“ ä¿®å¤ï¼špower iterationä¸éœ€è¦æ¢¯åº¦
        with torch.no_grad():
            v = torch.randn(A0.size(0), device=A0.device)  # (d,)
            for _ in range(n_iterations):
                v = A0 @ v
                v = v / (v.norm() + 1e-8)
            spec = (v @ (A0 @ v)).abs()

        # æƒ©ç½šé¡¹éœ€è¦æ¢¯åº¦ï¼Œæ‰€ä»¥åœ¨no_gradå¤–è®¡ç®—
        if spec > max_allowed:
            penalty = penalty + (spec - max_allowed) ** 2

    # å¯¹æ¯ä¸ªå“åº”åŸº B_k è®¡ç®—è°±èŒƒæ•°
    for k in range(self.K):
        Bk = self.B[k]  # (d, d)

        with torch.no_grad():
            v = torch.randn(Bk.size(0), device=Bk.device)  # (d,)
            for _ in range(n_iterations):
                v = Bk @ v
                v = v / (v.norm() + 1e-8)
            spec = (v @ (Bk @ v)).abs()

        if spec > max_allowed:
            penalty = penalty + (spec - max_allowed) ** 2

    return penalty
```

---

### ä¿®å¤1.3ï¼štrain_*_core.py æ–‡ä»¶ç¼–ç é—®é¢˜

**æ–‡ä»¶**ï¼š
- `src/train/train_operator_core.py`
- `src/train/train_embed_core.py`

**ä¸¥é‡æ€§**ï¼šğŸ”´ é«˜ï¼ˆæ— æ³•å¯¼å…¥ï¼‰
**ä¿®å¤æ—¶é—´**ï¼š15åˆ†é’Ÿ

**é—®é¢˜æè¿°**ï¼š
æ–‡ä»¶ç¼–ç æŸåï¼ˆå¯èƒ½æ˜¯GBKæˆ–å…¶ä»–ç¼–ç æ··å…¥UTF-8ï¼‰

**å¿«é€Ÿè¯Šæ–­**ï¼š
```bash
file src/train/train_*.py
# è¾“å‡º: dataï¼ˆè¡¨ç¤ºç¼–ç é”™è¯¯ï¼‰
```

**ä¿®å¤æ–¹æ¡ˆ**ï¼š

æ–¹æ¡ˆAï¼šå¦‚æœåŸå§‹æ–‡ä»¶å­˜å‚¨æœ‰å¤‡ä»½
```bash
# ä»gitå†å²æ¢å¤
git checkout HEAD -- src/train/train_operator_core.py
git checkout HEAD -- src/train/train_embed_core.py
```

æ–¹æ¡ˆBï¼šå¦‚æœéœ€è¦é‡æ–°ç¼–ç 
```bash
# æ£€æµ‹åŸå§‹ç¼–ç 
chardet src/train/train_operator_core.py

# è½¬æ¢ä¸ºUTF-8
iconv -f GBK -t UTF-8 src/train/train_operator_core.py -o temp.py
mv temp.py src/train/train_operator_core.py

iconv -f GBK -t UTF-8 src/train/train_embed_core.py -o temp.py
mv temp.py src/train/train_embed_core.py
```

æ–¹æ¡ˆCï¼šé‡æ–°ç”Ÿæˆæ–‡ä»¶
å¦‚æœä¸Šè¿°æ–¹æ¡ˆæ— æ³•å·¥ä½œï¼Œéœ€è¦é‡æ–°ç¼–å†™è¿™ä¸¤ä¸ªæ–‡ä»¶ã€‚å¯å‚è€ƒsuanfa.mdçš„ç¬¬384-451å’Œ352-383è¡Œ

**éªŒè¯æ–¹æ¡ˆ**ï¼š
```bash
# éªŒè¯ç¼–ç æ­£ç¡®
file src/train/train_*.py
# åº”è¾“å‡ºï¼šUTF-8 Unicode text

# å°è¯•å¯¼å…¥
python -c "from src.train.train_operator_core import train_operator"
```

---

## ä¼˜å…ˆçº§2ï¼ˆæœ¬å‘¨å®Œæˆï¼‰

### ä¿®å¤2.1ï¼šedistance.py åˆ†å—ç‰ˆæœ¬æ¢¯åº¦é—®é¢˜

**æ–‡ä»¶**ï¼š`src/utils/edistance.py`
**è¡Œå·**ï¼š243, 253, 262
**ä¸¥é‡æ€§**ï¼šğŸŸ¡ ä¸­ï¼ˆå½±å“åå‘ä¼ æ’­ï¼‰
**ä¿®å¤æ—¶é—´**ï¼š10åˆ†é’Ÿ

**é—®é¢˜æè¿°**ï¼š
```python
# å½“å‰ä»£ç 
term_xy += d_xy_batch.sum().item()  # âŒ .item()ç ´åæ¢¯åº¦
```

**ä¿®å¤æ–¹æ¡ˆ**ï¼š

```python
def energy_distance_batched(
    x: torch.Tensor,
    y: torch.Tensor,
    batch_size: int = 1000,
    requires_grad: bool = False  # æ–°å‚æ•°
) -> torch.Tensor:
    """
    åˆ†å—è®¡ç®—E-distanceï¼Œç”¨äºå¤§è§„æ¨¡æ•°æ®

    å‚æ•°:
        x: (n, d) ç¬¬ä¸€ç»„æ ·æœ¬
        y: (m, d) ç¬¬äºŒç»„æ ·æœ¬
        batch_size: åˆ†å—å¤§å°
        requires_grad: æ˜¯å¦éœ€è¦æ¢¯åº¦ï¼ˆå½±å“æ€§èƒ½ï¼‰

    è¿”å›:
        ed2: æ ‡é‡ï¼Œèƒ½é‡è·ç¦»çš„å¹³æ–¹
    """
    n, m = x.size(0), y.size(0)

    if n == 0 or m == 0:
        return torch.tensor(0.0, device=x.device)

    # âœ“ ä¿®å¤ï¼šä½¿ç”¨å¼ é‡è€Œéæ ‡é‡ç´¯åŠ 
    if requires_grad:
        # éœ€è¦æ¢¯åº¦æ—¶ï¼Œä¿æŒå¼ é‡å½¢å¼
        term_xy = torch.tensor(0.0, device=x.device, dtype=x.dtype)
        for i in range(0, n, batch_size):
            x_batch = x[i:i + batch_size]
            for j in range(0, m, batch_size):
                y_batch = y[j:j + batch_size]
                d_xy_batch = pairwise_distances(x_batch, y_batch)
                term_xy = term_xy + d_xy_batch.sum()
        term_xy = 2.0 / (n * m) * term_xy
    else:
        # ä¸éœ€è¦æ¢¯åº¦æ—¶ï¼Œä½¿ç”¨.item()ä¼˜åŒ–å†…å­˜
        term_xy_sum = 0.0
        for i in range(0, n, batch_size):
            x_batch = x[i:i + batch_size]
            for j in range(0, m, batch_size):
                y_batch = y[j:j + batch_size]
                d_xy_batch = pairwise_distances(x_batch, y_batch)
                term_xy_sum += d_xy_batch.sum().item()
        term_xy = 2.0 / (n * m) * term_xy_sum

    # term_xxå’Œterm_yyç±»ä¼¼å¤„ç†...
    term_xx = torch.tensor(0.0, device=x.device, dtype=x.dtype) if requires_grad else 0.0
    for i in range(0, n, batch_size):
        x_batch_i = x[i:i + batch_size]
        for j in range(0, n, batch_size):
            x_batch_j = x[j:j + batch_size]
            d_xx_batch = pairwise_distances(x_batch_i, x_batch_j)
            if requires_grad:
                term_xx = term_xx + d_xx_batch.sum()
            else:
                term_xx += d_xx_batch.sum().item()
    if requires_grad:
        term_xx = 1.0 / (n * n) * term_xx
    else:
        term_xx = 1.0 / (n * n) * term_xx

    # term_yyç±»ä¼¼...
    term_yy = torch.tensor(0.0, device=y.device, dtype=y.dtype) if requires_grad else 0.0
    for i in range(0, m, batch_size):
        y_batch_i = y[i:i + batch_size]
        for j in range(0, m, batch_size):
            y_batch_j = y[j:j + batch_size]
            d_yy_batch = pairwise_distances(y_batch_i, y_batch_j)
            if requires_grad:
                term_yy = term_yy + d_yy_batch.sum()
            else:
                term_yy += d_yy_batch.sum().item()
    if requires_grad:
        term_yy = 1.0 / (m * m) * term_yy
    else:
        term_yy = 1.0 / (m * m) * term_yy

    if isinstance(term_xy, torch.Tensor):
        ed2 = term_xy - term_xx - term_yy
    else:
        ed2 = torch.tensor(term_xy - term_xx - term_yy, device=x.device, dtype=x.dtype)

    return ed2
```

---

### ä¿®å¤2.2ï¼šoperator.py ä½¿ç”¨einsumä¼˜åŒ–å†…å­˜

**æ–‡ä»¶**ï¼š`src/models/operator.py`
**è¡Œå·**ï¼š184-198
**ä¸¥é‡æ€§**ï¼šğŸŸ¡ ä¸­ï¼ˆå†…å­˜å ç”¨é«˜ï¼‰
**ä¿®å¤æ—¶é—´**ï¼š10åˆ†é’Ÿ
**æ€§èƒ½æå‡**ï¼š5å€å†…å­˜èŠ‚çœ

**é—®é¢˜æè¿°**ï¼š
```python
# å½“å‰ä»£ç ï¼šO(B*K*dÂ²)å†…å­˜
B_expand = self.B.unsqueeze(0).expand(B, -1, -1, -1)
alpha_expand = alpha.view(B, self.K, 1, 1)
A_res = (alpha_expand * B_expand).sum(dim=1)
```

**ä¿®å¤æ–¹æ¡ˆ**ï¼š

```python
def forward(self, z, tissue_idx, cond_vec):
    """å‰å‘ä¼ æ’­ï¼šåº”ç”¨ç®—å­"""
    B = z.size(0)
    d = self.latent_dim

    # è®¡ç®—å“åº”åŸºçš„æ¿€æ´»ç³»æ•°
    alpha = self.alpha_mlp(cond_vec)  # (B, K)
    beta = self.beta_mlp(cond_vec)    # (B, K)

    # è·å–å¯¹åº”ç»„ç»‡çš„åŸºçº¿ç®—å­
    A0 = self.A0_tissue[tissue_idx]   # (B, d, d)
    b0 = self.b0_tissue[tissue_idx]   # (B, d)

    # âœ“ ä¿®å¤ï¼šä½¿ç”¨einsumé¿å…æ˜¾å¼æ‰©å±•
    # åŸå§‹ï¼šA_res = (alpha_expand * B_expand).sum(dim=1)
    # ä¼˜åŒ–ï¼šA_res = torch.einsum('bk,kij->bij', alpha, self.B)
    A_res = torch.einsum('bk,kij->bij', alpha, self.B)  # (B, d, d)

    # æœ€ç»ˆç®—å­
    A_theta = A0 + A_res  # (B, d, d)

    # å¹³ç§»åŸºä¹Ÿä½¿ç”¨einsum
    b_res = torch.einsum('bk,ki->bi', beta, self.u)  # (B, d)

    # æœ€ç»ˆå¹³ç§»
    b_theta = b0 + b_res  # (B, d)

    # åº”ç”¨ç®—å­
    z_out = torch.bmm(A_theta, z.unsqueeze(-1)).squeeze(-1) + b_theta

    return z_out, A_theta, b_theta
```

**æ€§èƒ½å¯¹æ¯”**ï¼š
```
ä¼˜åŒ–å‰ï¼š
  batch=64, K=5, d=32: ~40MBå†…å­˜å ç”¨

ä¼˜åŒ–åï¼ˆeinsumï¼‰ï¼š
  batch=64, K=5, d=32: ~8MBå†…å­˜å ç”¨
  æ€§èƒ½æå‡ï¼š5å€
```

---

### ä¿®å¤2.3ï¼švirtual_cell.py Pearsonç›¸å…³ç³»æ•°å‘é‡åŒ–

**æ–‡ä»¶**ï¼š`src/utils/virtual_cell.py`
**è¡Œå·**ï¼š339-350
**ä¸¥é‡æ€§**ï¼šğŸŸ¡ ä¸­ï¼ˆè®¡ç®—æ…¢ï¼‰
**ä¿®å¤æ—¶é—´**ï¼š10åˆ†é’Ÿ
**æ€§èƒ½æå‡**ï¼š10-20å€

**é—®é¢˜æè¿°**ï¼š
```python
# å½“å‰ä»£ç ï¼šforå¾ªç¯ï¼ŒO(B)ä¸ªæ“ä½œ
for i in range(B):
    x_i = x[i]
    x_recon_i = x_recon[i]
    # ... è®¡ç®—ç›¸å…³ç³»æ•° ...
```

**ä¿®å¤æ–¹æ¡ˆ**ï¼š

```python
@torch.no_grad()
def compute_reconstruction_error(
    vae: NBVAE,
    x: torch.Tensor,
    tissue_onehot: torch.Tensor,
    device: str = "cuda"
) -> Tuple[torch.Tensor, torch.Tensor]:
    """
    è®¡ç®—VAEçš„é‡å»ºè¯¯å·®ï¼ˆç”¨äºè´¨é‡è¯„ä¼°ï¼‰

    å‚æ•°:
        vae: NB-VAEæ¨¡å‹
        x: (B, G) åŸå§‹åŸºå› è¡¨è¾¾
        tissue_onehot: (B, n_tissues) ç»„ç»‡one-hot
        device: è®¾å¤‡

    è¿”å›:
        mse: (B,) æ¯ä¸ªæ ·æœ¬çš„MSE
        correlation: (B,) æ¯ä¸ªæ ·æœ¬çš„Pearsonç›¸å…³ç³»æ•°
    """
    # ç¼–ç -è§£ç 
    z = encode_cells(vae, x, tissue_onehot, device)
    x_recon = decode_cells(vae, z, tissue_onehot, device)

    # MSE
    mse = ((x - x_recon) ** 2).mean(dim=-1)  # (B,)

    # âœ“ ä¿®å¤ï¼šå‘é‡åŒ–è®¡ç®—Pearsonç›¸å…³ç³»æ•°
    # ä¸­å¿ƒåŒ–
    x_centered = x - x.mean(dim=-1, keepdim=True)  # (B, G)
    xr_centered = x_recon - x_recon.mean(dim=-1, keepdim=True)  # (B, G)

    # ç›¸å…³ç³»æ•°å‘é‡åŒ–
    numerator = (x_centered * xr_centered).sum(dim=-1)  # (B,)
    denominator = torch.sqrt(
        (x_centered ** 2).sum(dim=-1) * (xr_centered ** 2).sum(dim=-1) + 1e-8
    )  # (B,)
    correlation = numerator / denominator  # (B,)

    return mse, correlation
```

**æ€§èƒ½å¯¹æ¯”**ï¼š
```
ä¼˜åŒ–å‰ï¼ˆforå¾ªç¯ï¼‰ï¼š
  B=1000, G=2000: ~50ms

ä¼˜åŒ–åï¼ˆå‘é‡åŒ–ï¼‰ï¼š
  B=1000, G=2000: ~2ms
  æ€§èƒ½æå‡ï¼š25å€
```

---

## ä¼˜å…ˆçº§3ï¼ˆæœ¬æœˆå®Œæˆï¼‰

### ä¿®å¤3.1ï¼šcond_encoder.py ç±»å‹æç¤ºä¿®å¤

**æ–‡ä»¶**ï¼š`src/utils/cond_encoder.py`
**è¡Œå·**ï¼š135, 209
**ä¸¥é‡æ€§**ï¼šğŸŸ¢ ä½ï¼ˆç±»å‹æ£€æŸ¥å·¥å…·æŠ¥é”™ï¼‰
**ä¿®å¤æ—¶é—´**ï¼š2åˆ†é’Ÿ

```python
# ä¿®å¤å‰
from typing import Dict, Optional, List
def encode_obs_row(self, obs_row: Dict[str, any], ...):
def forward(self, obs_rows: List[Dict[str, any]]) -> torch.Tensor:

# ä¿®å¤å
from typing import Dict, Optional, List, Any  # æ·»åŠ Any
def encode_obs_row(self, obs_row: Dict[str, Any], ...):
def forward(self, obs_rows: List[Dict[str, Any]]) -> torch.Tensor:
```

---

### ä¿®å¤3.2ï¼šscperturb_dataset.py ç´¢å¼•é—®é¢˜

**æ–‡ä»¶**ï¼š`src/data/scperturb_dataset.py`
**è¡Œå·**ï¼š207-213
**ä¸¥é‡æ€§**ï¼šğŸŸ¡ ä¸­ï¼ˆå¯èƒ½å¯¼è‡´è¿è¡Œæ—¶é”™è¯¯ï¼‰
**ä¿®å¤æ—¶é—´**ï¼š10åˆ†é’Ÿ

```python
# é—®é¢˜ä»£ç 
for i0, i1 in zip(t0_sampled, t1_sampled):
    obs_dict = obs_df.iloc[self.adata.obs.index.get_loc(i0)].to_dict()
    pairs.append((
        self.adata.obs.index.get_loc(i0),
        self.adata.obs.index.get_loc(i1),
        obs_dict
    ))

# ä¿®å¤ä»£ç 
for i0, i1 in zip(t0_sampled, t1_sampled):
    # i0å’Œi1å·²ç»æ˜¯æ ‡ç­¾ï¼Œç›´æ¥ç”¨get_locè½¬æ¢ä¸ºä½ç½®ç´¢å¼•
    pos0 = self.adata.obs.index.get_loc(i0)
    pos1 = self.adata.obs.index.get_loc(i1)
    obs_dict = self.adata.obs.iloc[pos0].to_dict()
    pairs.append((pos0, pos1, obs_dict))
```

---

### ä¿®å¤3.3ï¼šæ•°å€¼ç¨³å®šæ€§å‚æ•°ç»Ÿä¸€

**æ–‡ä»¶**ï¼š`src/config.py`
**ä»»åŠ¡**ï¼šåˆ›å»ºç»Ÿä¸€çš„æ•°å€¼ç¨³å®šæ€§å‚æ•°

```python
# æ·»åŠ åˆ°config.py
class NumericalStabilityConfig:
    """æ•°å€¼ç¨³å®šæ€§ç›¸å…³å‚æ•°"""

    # E-distanceè®¡ç®—
    PAIRWISE_DISTANCE_EPSILON = 1e-7  # pairwise_distancesä¸­çš„epsilon

    # è´ŸäºŒé¡¹åˆ†å¸ƒ
    NB_LIKELIHOOD_EPSILON = 1e-8  # logè®¡ç®—çš„epsilon

    # è°±èŒƒæ•°è®¡ç®—
    SPECTRAL_NORM_EPSILON = 1e-8  # power iterationçš„epsilon
    POWER_ITERATION_STEPS = 5     # power iterationçš„è¿­ä»£æ¬¡æ•°

    # VAE
    VAE_EPSILON = 1e-8            # softpluså’Œlogçš„epsilon
```

---

## ä¿®å¤éªŒè¯æ¸…å•

å®Œæˆæ¯ä¸ªä¿®å¤åï¼Œè¯·æ£€æŸ¥ï¼š

- [ ] ä»£ç è¯­æ³•æ­£ç¡®ï¼ˆpython -m py_compileï¼‰
- [ ] èƒ½æ­£å¸¸å¯¼å…¥ï¼ˆpython -c "from ... import ..."ï¼‰
- [ ] å•å…ƒæµ‹è¯•é€šè¿‡
- [ ] git diff æ£€æŸ¥ä¿®æ”¹å†…å®¹
- [ ] æäº¤ä¿¡æ¯æ¸…æ™°ï¼ˆå‚è€ƒCLAUDE.mdè§„èŒƒï¼‰

---

## ä¿®å¤æ—¶é—´è¡¨

| ä¿®å¤ | ä¼˜å…ˆçº§ | éš¾åº¦ | é¢„æœŸæ—¶é—´ | å®Œæˆæ—¥æœŸ |
|------|--------|------|----------|----------|
| 1.1 éšæœºç§å­ | P1 | ä½ | 5åˆ†é’Ÿ | _ |
| 1.2 power iteration | P1 | ä½ | 5åˆ†é’Ÿ | _ |
| 1.3 æ–‡ä»¶ç¼–ç  | P1 | ä¸­ | 15åˆ†é’Ÿ | _ |
| 2.1 æ¢¯åº¦é—®é¢˜ | P2 | ä¸­ | 10åˆ†é’Ÿ | _ |
| 2.2 einsumä¼˜åŒ– | P2 | ä½ | 10åˆ†é’Ÿ | _ |
| 2.3 ç›¸å…³ç³»æ•° | P2 | ä½ | 10åˆ†é’Ÿ | _ |
| 3.1 ç±»å‹æç¤º | P3 | æä½ | 2åˆ†é’Ÿ | _ |
| 3.2 ç´¢å¼•é—®é¢˜ | P3 | ä½ | 10åˆ†é’Ÿ | _ |
| 3.3 å‚æ•°ç»Ÿä¸€ | P3 | ä½ | 10åˆ†é’Ÿ | _ |

**æ€»è®¡**ï¼š67åˆ†é’Ÿ

---

## æµ‹è¯•éªŒè¯è„šæœ¬

è¿è¡Œæä¾›çš„æµ‹è¯•è„šæœ¬éªŒè¯ä¿®å¤ï¼š
```bash
cd /home/user/xuni
python .claude/test_core_modules.py
```

é¢„æœŸè¾“å‡ºï¼š
```
âœ“ NBVAEæ¨¡å—æµ‹è¯•é€šè¿‡
âœ“ OperatorModelæ¨¡å—æµ‹è¯•é€šè¿‡
âœ“ E-distanceæ¨¡å—æµ‹è¯•é€šè¿‡
âœ“ æ¡ä»¶ç¼–ç å™¨æµ‹è¯•é€šè¿‡
âœ“ è™šæ‹Ÿç»†èƒæ¥å£æµ‹è¯•é€šè¿‡
âœ“ æ€§èƒ½æµ‹è¯•å®Œæˆ

âœ“ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼
```

