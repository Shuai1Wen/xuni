# æ ¸å¿ƒæ¨¡å‹æ–‡ä»¶ä»£ç å®¡æŸ¥æŠ¥å‘Š

ç”Ÿæˆæ—¶é—´ï¼š2025-11-18
å®¡æŸ¥æ–‡ä»¶ï¼š
1. src/models/nb_vae.py
2. src/models/operator.py

---

## æ‰§è¡Œæ‘˜è¦

æ€»ä½“è¯„åˆ†ï¼š**82/100**

å‘ç°é—®é¢˜ç»Ÿè®¡ï¼š
- ä¸¥é‡é—®é¢˜ï¼š1ä¸ªï¼ˆè°±èŒƒæ•°è®¡ç®—æ–¹æ³•é”™è¯¯ï¼‰
- ä¸­ç­‰é—®é¢˜ï¼š2ä¸ªï¼ˆæ•°å€¼ç¨³å®šæ€§ã€å¼ é‡æ¯”è¾ƒï¼‰
- è½»å¾®é—®é¢˜ï¼š2ä¸ªï¼ˆæ€§èƒ½ä¼˜åŒ–ã€ä»£ç é£æ ¼ï¼‰

å»ºè®®ï¼š**éœ€è¦ä¿®å¤ä¸¥é‡å’Œä¸­ç­‰é—®é¢˜åå†éƒ¨ç½²**

---

## è¯¦ç»†é—®é¢˜æ¸…å•

### ä¸¥é‡é—®é¢˜ï¼ˆå¿…é¡»ä¿®å¤ï¼‰

#### é—®é¢˜1ï¼šè°±èŒƒæ•°ï¼ˆSpectral Normï¼‰è®¡ç®—æ–¹æ³•é”™è¯¯

**ä½ç½®**ï¼š`src/models/operator.py:274-285` å’Œ `src/models/operator.py:401-407`

**ä¸¥é‡ç¨‹åº¦**ï¼šâš ï¸ ä¸¥é‡

**é—®é¢˜æè¿°**ï¼š

å½“å‰å®ç°ä½¿ç”¨Power Iterationè®¡ç®—çš„æ˜¯**æœ€å¤§ç‰¹å¾å€¼**ï¼Œè€Œé**è°±èŒƒæ•°**ï¼ˆæœ€å¤§å¥‡å¼‚å€¼ï¼‰ã€‚

```python
# å½“å‰ä»£ç ï¼ˆé”™è¯¯ï¼‰
with torch.no_grad():
    v = torch.randn(A0.size(0), device=A0.device)
    for _ in range(n_iterations):
        v = A0 @ v  # â† é—®é¢˜ï¼šåªå¯¹Aè¿­ä»£
        v = v / (v.norm() + _NUM_CFG.eps_division)

v_detached = v.detach()
spec = (v_detached @ (A0 @ v_detached)).abs()  # â† è¿™æ˜¯Rayleighå•†ï¼Œè®¡ç®—ç‰¹å¾å€¼
```

**æ•°å­¦åˆ†æ**ï¼š

1. **è°±èŒƒæ•°å®šä¹‰**ï¼š||A||â‚‚ = Ïƒ_max(A)ï¼Œå³æœ€å¤§å¥‡å¼‚å€¼
2. **å½“å‰å®ç°è®¡ç®—çš„æ˜¯**ï¼šÎ»_max(A)ï¼Œå³æœ€å¤§ç‰¹å¾å€¼
3. **å·®å¼‚**ï¼š
   - å¯¹äºå¯¹ç§°çŸ©é˜µï¼š||A||â‚‚ = |Î»_max(A)|ï¼ˆç›¸ç­‰ï¼‰
   - å¯¹äºä¸€èˆ¬çŸ©é˜µï¼š||A||â‚‚ â‰  |Î»_max(A)|ï¼ˆä¸ç›¸ç­‰ï¼‰
   - ç‰¹å¾å€¼å¯èƒ½æ˜¯å¤æ•°ï¼Œä½†å¥‡å¼‚å€¼æ€»æ˜¯å®æ•°éè´Ÿ

**æ­£ç¡®å®ç°åº”è¯¥**ï¼š

```python
# æ–¹æ³•1ï¼šå¯¹A^T Aè¿›è¡ŒPower Iteration
with torch.no_grad():
    v = torch.randn(A0.size(0), device=A0.device)
    for _ in range(n_iterations):
        v = A0.T @ (A0 @ v)  # A^T A v
        v = v / (v.norm() + _NUM_CFG.eps_division)

v_detached = v.detach()
spec = torch.sqrt((v_detached @ (A0.T @ (A0 @ v_detached))).abs())

# æ–¹æ³•2ï¼šä½¿ç”¨PyTorchå†…ç½®å‡½æ•°ï¼ˆæ›´å‡†ç¡®ä½†ä¸å¯å¾®ï¼‰
spec = torch.linalg.matrix_norm(A0, ord=2)
```

**å½±å“èŒƒå›´**ï¼š
- `spectral_penalty()` æ–¹æ³•ï¼šç¨³å®šæ€§æ­£åˆ™åŒ–å¯èƒ½ä¸å‡†ç¡®
- `compute_operator_norm()` æ–¹æ³•ï¼šç›‘æ§çš„èŒƒæ•°å€¼ä¸æ˜¯çœŸå®çš„è°±èŒƒæ•°
- è®­ç»ƒç¨³å®šæ€§ï¼šå¦‚æœåŸºçº¿ç®—å­A_t^(0)æˆ–å“åº”åŸºB_kæ˜¯éå¯¹ç§°çš„ï¼Œçº¦æŸå¯èƒ½å¤±æ•ˆ

**ä¿®å¤ä¼˜å…ˆçº§**ï¼šğŸ”´ é«˜ï¼ˆå½±å“æ¨¡å‹ç¨³å®šæ€§ä¿è¯ï¼‰

---

### ä¸­ç­‰é—®é¢˜ï¼ˆå»ºè®®ä¿®å¤ï¼‰

#### é—®é¢˜2ï¼šè´ŸäºŒé¡¹å¯¹æ•°ä¼¼ç„¶å‡½æ•°çš„æ•°å€¼ç¨³å®šæ€§ä¸è¶³

**ä½ç½®**ï¼š`src/models/nb_vae.py:311-312`

**ä¸¥é‡ç¨‹åº¦**ï¼šâš ï¸ ä¸­ç­‰

**é—®é¢˜æè¿°**ï¼š

epsilonçš„æ·»åŠ ä½ç½®ä¸æ­£ç¡®ï¼Œå¯èƒ½åœ¨æç«¯æƒ…å†µä¸‹ä»ç„¶å¯¼è‡´æ•°å€¼ä¸ç¨³å®šã€‚

```python
# å½“å‰ä»£ç 
log_r_over_r_plus_mu = torch.log(r / (r + mu) + eps)     # (B, G)
log_mu_over_r_plus_mu = torch.log(mu / (r + mu) + eps)   # (B, G)
```

**é—®é¢˜åˆ†æ**ï¼š

1. **å½“å‰é€»è¾‘**ï¼šå…ˆè®¡ç®—æ¯”å€¼ `r/(r+mu)`ï¼Œç„¶ååŠ epsilonï¼Œæœ€åå–log
2. **é—®é¢˜åœºæ™¯**ï¼š
   - å¦‚æœ `r=1e-10, mu=100`ï¼Œåˆ™ `r/(r+mu) â‰ˆ 1e-12`
   - åŠ ä¸Š `eps=1e-8` åï¼š`1e-12 + 1e-8 â‰ˆ 1e-8`
   - ç»“æœï¼š`log(1e-8) = -18.42`ï¼ˆè™½ç„¶æœ‰é™ï¼Œä½†epsilonçš„ä½œç”¨è¢«å‰Šå¼±ï¼‰
3. **æ›´ç³Ÿçš„æƒ…å†µ**ï¼š
   - å¦‚æœæ¯”å€¼æœ¬èº«å°±æ˜¯0ï¼ˆæµ®ç‚¹ä¸‹æº¢ï¼‰ï¼ŒåŠ epsilonåæ‰å˜æˆ1e-8
   - å¦‚æœepsilonå¤ªå°ï¼ˆå¦‚1e-16ï¼‰ï¼Œä»ç„¶å¯èƒ½log(0)

**æ­£ç¡®å®ç°**ï¼š

```python
# æ–¹æ³•1ï¼šåœ¨åˆ†å­åˆ†æ¯éƒ½åŠ epsilon
log_r_over_r_plus_mu = torch.log((r + eps) / (r + mu + eps))
log_mu_over_r_plus_mu = torch.log((mu + eps) / (r + mu + eps))

# æ–¹æ³•2ï¼šä½¿ç”¨logçš„å‡æ³•æ€§è´¨ï¼ˆæœ€ä½³ï¼‰
log_r_over_r_plus_mu = torch.log(r + eps) - torch.log(r + mu + eps)
log_mu_over_r_plus_mu = torch.log(mu + eps) - torch.log(r + mu + eps)
```

**æ–¹æ³•2çš„ä¼˜åŠ¿**ï¼š
- å¯¹æ•°è¿ç®—çš„æ•°å€¼ç¨³å®šæ€§æ›´å¥½
- é¿å…äº†é™¤æ³•è¿ç®—ï¼ˆé™¤æ³•æ¯”å‡æ³•æ›´å®¹æ˜“äº§ç”Ÿæ•°å€¼è¯¯å·®ï¼‰
- PyTorchçš„logå¯¹å°å€¼æœ‰ç‰¹æ®Šä¼˜åŒ–

**å½±å“èŒƒå›´**ï¼š
- å½“muæˆ–ræ¥è¿‘0æ—¶ï¼Œé‡å»ºæŸå¤±å¯èƒ½ä¸å‡†ç¡®
- æç«¯æƒ…å†µä¸‹å¯èƒ½äº§ç”ŸNaNæˆ–Infï¼Œå¯¼è‡´è®­ç»ƒå´©æºƒ

**ä¿®å¤ä¼˜å…ˆçº§**ï¼šğŸŸ¡ ä¸­ï¼ˆå·²æœ‰éƒ¨åˆ†ä¿æŠ¤ï¼Œä½†ä¸å¤Ÿé²æ£’ï¼‰

---

#### é—®é¢˜3ï¼šè°±èŒƒæ•°æƒ©ç½šä¸­çš„å¼ é‡æ¯”è¾ƒé€»è¾‘é—®é¢˜

**ä½ç½®**ï¼š`src/models/operator.py:288-289` å’Œ `src/models/operator.py:306-307`

**ä¸¥é‡ç¨‹åº¦**ï¼šâš ï¸ ä¸­ç­‰

**é—®é¢˜æè¿°**ï¼š

åœ¨ifæ¡ä»¶ä¸­ç›´æ¥æ¯”è¾ƒæ ‡é‡å¼ é‡å¯èƒ½è§¦å‘è­¦å‘Šæˆ–åœ¨æœªæ¥ç‰ˆæœ¬çš„PyTorchä¸­æŠ¥é”™ã€‚

```python
# å½“å‰ä»£ç 
spec = (v_detached @ (A0 @ v_detached)).abs()  # æ ‡é‡å¼ é‡
if spec > max_allowed:  # â† å¼ é‡æ¯”è¾ƒ
    penalty = penalty + (spec - max_allowed) ** 2
```

**é—®é¢˜åˆ†æ**ï¼š

1. **å½“å‰è¡Œä¸º**ï¼š
   - `spec` æ˜¯ä¸€ä¸ª0ç»´å¼ é‡ï¼ˆæ ‡é‡å¼ é‡ï¼‰
   - `spec > max_allowed` è¿”å›ä¸€ä¸ªboolå¼ é‡
   - åœ¨Python ifä¸­ä½¿ç”¨boolå¼ é‡ä¼šè§¦å‘éšå¼è½¬æ¢
   - PyTorchä¼šå‘å‡ºè­¦å‘Šï¼š`UserWarning: Converting a tensor to a Python boolean might cause trace to be incorrect`

2. **æ½œåœ¨é—®é¢˜**ï¼š
   - TorchScriptç¼–è¯‘æ—¶å¯èƒ½å‡ºé”™
   - ä½¿ç”¨JITè¿½è¸ªæ—¶è¡Œä¸ºä¸ç¡®å®š
   - æœªæ¥PyTorchç‰ˆæœ¬å¯èƒ½ç¦æ­¢è¿™ç§ç”¨æ³•

**æ­£ç¡®å®ç°**ï¼š

```python
# æ–¹æ³•1ï¼šä½¿ç”¨.item()è½¬æ¢ä¸ºPythonæ ‡é‡
spec_val = spec.item()
if spec_val > max_allowed:
    penalty = penalty + (spec - max_allowed) ** 2

# æ–¹æ³•2ï¼šä½¿ç”¨ReLUé¿å…ifï¼ˆæ¨èï¼Œä¿æŒå¯å¾®æ€§ï¼‰
excess = spec - max_allowed
penalty = penalty + F.relu(excess) ** 2

# æ–¹æ³•3ï¼šä½¿ç”¨torch.clamp
excess = torch.clamp(spec - max_allowed, min=0.0)
penalty = penalty + excess ** 2
```

**æ–¹æ³•2å’Œ3çš„ä¼˜åŠ¿**ï¼š
- å®Œå…¨å¯å¾®ï¼ˆè™½ç„¶åœ¨with torch.no_grad()å¤–ä½¿ç”¨ï¼‰
- é¿å…åˆ†æ”¯ï¼Œæ›´é€‚åˆå‘é‡åŒ–å’ŒJITç¼–è¯‘
- ä»£ç æ›´ç®€æ´

**å½±å“èŒƒå›´**ï¼š
- å½“å‰åŠŸèƒ½æ­£å¸¸ï¼Œä½†å¯èƒ½åœ¨TorchScriptç¼–è¯‘æ—¶å‡ºé”™
- å½±å“ä»£ç çš„å¯ç§»æ¤æ€§å’Œæœªæ¥å…¼å®¹æ€§

**ä¿®å¤ä¼˜å…ˆçº§**ï¼šğŸŸ¡ ä¸­ï¼ˆåŠŸèƒ½æ€§æ— å½±å“ï¼Œä½†å½±å“ä»£ç è´¨é‡ï¼‰

---

### è½»å¾®é—®é¢˜ï¼ˆå¯é€‰ä¼˜åŒ–ï¼‰

#### é—®é¢˜4ï¼šcompute_operator_normæ–¹æ³•æœªå‘é‡åŒ–

**ä½ç½®**ï¼š`src/models/operator.py:401-407`

**ä¸¥é‡ç¨‹åº¦**ï¼šâ„¹ï¸ è½»å¾®

**é—®é¢˜æè¿°**ï¼š

ä½¿ç”¨forå¾ªç¯éå†batchä¸­çš„æ¯ä¸ªæ ·æœ¬ï¼Œæœªå……åˆ†åˆ©ç”¨PyTorchçš„å‘é‡åŒ–èƒ½åŠ›ã€‚

```python
# å½“å‰ä»£ç 
norms = torch.zeros(B, device=A_theta.device)
for i in range(B):  # â† æœªå‘é‡åŒ–
    v = torch.randn(self.latent_dim, device=A_theta.device)
    for _ in range(5):
        v = A_theta[i] @ v
        v = v / (v.norm() + _NUM_CFG.eps_division)
    norms[i] = (v @ (A_theta[i] @ v)).abs()
```

**æ€§èƒ½å½±å“**ï¼š

- å¯¹äºbatch_size=128, latent_dim=32ï¼š
  - å½“å‰å®ç°ï¼š128æ¬¡é¡ºåºè¿­ä»£ï¼Œæ— æ³•å¹¶è¡Œ
  - å‘é‡åŒ–å®ç°ï¼šæ‰€æœ‰æ ·æœ¬å¹¶è¡Œå¤„ç†
  - é¢„è®¡åŠ é€Ÿæ¯”ï¼š10-20å€ï¼ˆå–å†³äºç¡¬ä»¶ï¼‰

**ä¼˜åŒ–å®ç°**ï¼š

```python
# å‘é‡åŒ–ç‰ˆæœ¬
v = torch.randn(B, self.latent_dim, device=A_theta.device)  # (B, d)
for _ in range(5):
    # v â† A_theta @ v: (B, d, d) @ (B, d, 1) â†’ (B, d, 1) â†’ (B, d)
    v = torch.bmm(A_theta, v.unsqueeze(-1)).squeeze(-1)
    # å½’ä¸€åŒ–ï¼š(B, d)
    v = v / (v.norm(dim=-1, keepdim=True) + _NUM_CFG.eps_division)

# è®¡ç®—Rayleighå•†ï¼šv^T A v
# (B, 1, d) @ (B, d, d) @ (B, d, 1) â†’ (B, 1, 1) â†’ (B,)
norms = torch.bmm(
    v.unsqueeze(1),
    torch.bmm(A_theta, v.unsqueeze(-1))
).squeeze().abs()
```

**æ³¨æ„**ï¼š
- æ­¤æ–¹æ³•å¸¦æœ‰`@torch.no_grad()`è£…é¥°å™¨ï¼Œä»…ç”¨äºç›‘æ§
- ä¸å½±å“è®­ç»ƒæ€§èƒ½ï¼Œä»…å½±å“è¯„ä¼°/æ—¥å¿—è®°å½•çš„é€Ÿåº¦
- ä¼˜åŒ–ä¼˜å…ˆçº§ä¸é«˜

**ä¿®å¤ä¼˜å…ˆçº§**ï¼šğŸŸ¢ ä½ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼Œéå…³é”®è·¯å¾„ï¼‰

---

#### é—®é¢˜5ï¼šå˜é‡å‘½åå¯èƒ½å¼•èµ·æ··æ·†

**ä½ç½®**ï¼š`src/models/operator.py:172`

**ä¸¥é‡ç¨‹åº¦**ï¼šâ„¹ï¸ è½»å¾®

**é—®é¢˜æè¿°**ï¼š

å±€éƒ¨å˜é‡`B`ï¼ˆbatch sizeï¼‰ä¸ç±»å±æ€§`self.B`ï¼ˆå“åº”åŸºï¼‰åŒåï¼Œå¯èƒ½å¼•èµ·ä»£ç é˜…è¯»æ··æ·†ã€‚

```python
def forward(self, z, tissue_idx, cond_vec):
    B = z.size(0)  # batch size â† å˜é‡åB
    # ...
    A_res = torch.einsum('bk,kij->bij', alpha, self.B)  # self.Bæ˜¯å“åº”åŸº
```

**å½±å“**ï¼š
- åŠŸèƒ½æ— å½±å“ï¼ˆå±€éƒ¨å˜é‡ä¸ä¼šè¦†ç›–self.Bï¼‰
- ä»£ç å¯è¯»æ€§ç¨å·®
- æ–°è´¡çŒ®è€…å¯èƒ½å›°æƒ‘

**å»ºè®®ä¿®å¤**ï¼š

```python
# ä½¿ç”¨æ›´æ˜ç¡®çš„å˜é‡å
batch_size = z.size(0)
# æˆ–
B_batch = z.size(0)
```

**ä¿®å¤ä¼˜å…ˆçº§**ï¼šğŸŸ¢ ä½ï¼ˆä»£ç é£æ ¼é—®é¢˜ï¼‰

---

## ç»´åº¦ä¸€è‡´æ€§æ£€æŸ¥

### âœ… nb_vae.py ç»´åº¦ä¸€è‡´æ€§

| å‡½æ•°/æ–¹æ³• | è¾“å…¥ç»´åº¦ | è¾“å‡ºç»´åº¦ | çŠ¶æ€ |
|-----------|----------|----------|------|
| Encoder.forward | x: (B,G), tissue: (B,T) | mu: (B,d), logvar: (B,d) | âœ… æ­£ç¡® |
| DecoderNB.forward | z: (B,d), tissue: (B,T) | mu: (B,G), r: (1,G) | âœ… æ­£ç¡® |
| sample_z | mu: (B,d), logvar: (B,d) | z: (B,d) | âœ… æ­£ç¡® |
| nb_log_likelihood | x: (B,G), mu: (B,G), r: (1,G) | log_p: (B,) | âœ… æ­£ç¡® |
| elbo_loss | x: (B,G), tissue: (B,T) | loss: (), z: (B,d) | âœ… æ­£ç¡® |

**è¯´æ˜**ï¼š
- B: batch_size
- G: n_genes
- T: n_tissues
- d: latent_dim

### âœ… operator.py ç»´åº¦ä¸€è‡´æ€§

| å‡½æ•°/æ–¹æ³• | è¾“å…¥ç»´åº¦ | è¾“å‡ºç»´åº¦ | çŠ¶æ€ |
|-----------|----------|----------|------|
| OperatorModel.forward | z: (B,d), tissue: (B,), cond: (B,C) | z_out: (B,d), A: (B,d,d), b: (B,d) | âœ… æ­£ç¡® |
| spectral_penalty | - | penalty: () | âœ… æ­£ç¡® |
| get_response_profile | cond: (B,C) æˆ– (C,) | alpha: (B,K) æˆ– (K,), beta: (B,K) æˆ– (K,) | âœ… æ­£ç¡® |
| compute_operator_norm | tissue: (B,), cond: (B,C) | norms: (B,) | âœ… æ­£ç¡® |

**è¯´æ˜**ï¼š
- C: cond_dim
- K: n_response_bases

**ç»“è®º**ï¼šæ‰€æœ‰ç»´åº¦å˜æ¢æ­£ç¡®ï¼Œæœªå‘ç°ç»´åº¦ä¸åŒ¹é…é—®é¢˜ã€‚

---

## æ•°å­¦æ­£ç¡®æ€§æ£€æŸ¥

### âœ… nb_vae.py æ•°å­¦æ­£ç¡®æ€§

| ç»„ä»¶ | æ•°å­¦å…¬å¼ | å®ç°æ­£ç¡®æ€§ | å¤‡æ³¨ |
|------|----------|------------|------|
| é‡å‚æ•°åŒ–é‡‡æ · | z = Î¼ + ÏƒÎµ, Îµ~N(0,I) | âœ… æ­£ç¡® | std = exp(0.5*logvar) æ­£ç¡® |
| KLæ•£åº¦ | -0.5Â·Î£(1+logÏƒÂ²-Î¼Â²-ÏƒÂ²) | âœ… æ­£ç¡® | è§£æè§£å®ç°æ­£ç¡® |
| è´ŸäºŒé¡¹åˆ†å¸ƒ | log NB(x;Î¼,r) | âš ï¸ éƒ¨åˆ†æ­£ç¡® | å…¬å¼æ­£ç¡®ï¼Œä½†epsilonä½ç½®éœ€æ”¹è¿› |
| ELBO | E[log p(x\|z)] - Î²KL | âœ… æ­£ç¡® | æŸå¤±= -ELBO ç¬¦åˆæœ€å°åŒ–ç›®æ ‡ |

### âœ… operator.py æ•°å­¦æ­£ç¡®æ€§

| ç»„ä»¶ | æ•°å­¦å…¬å¼ | å®ç°æ­£ç¡®æ€§ | å¤‡æ³¨ |
|------|----------|------------|------|
| ç®—å­åº”ç”¨ | K_Î¸(z) = A_Î¸z + b_Î¸ | âœ… æ­£ç¡® | bmmå®ç°æ­£ç¡® |
| ä½ç§©åˆ†è§£ï¼ˆAï¼‰ | A_Î¸ = Aâ‚€ + Î£ Î±â‚–Bâ‚– | âœ… æ­£ç¡® | einsumå®ç°é«˜æ•ˆ |
| ä½ç§©åˆ†è§£ï¼ˆbï¼‰ | b_Î¸ = bâ‚€ + Î£ Î²â‚–uâ‚– | âœ… æ­£ç¡® | einsumå®ç°é«˜æ•ˆ |
| è°±èŒƒæ•°æƒ©ç½š | Î£ max(0, Ï(A)-Ïâ‚€)Â² | âŒ é”™è¯¯ | è®¡ç®—çš„æ˜¯ç‰¹å¾å€¼è€Œéè°±èŒƒæ•° |

---

## æ•°å€¼ç¨³å®šæ€§åˆ†æ

### nb_vae.py ç¨³å®šæ€§æªæ–½

| ä½ç½® | ç¨³å®šæ€§æªæ–½ | è¯„ä¼° |
|------|------------|------|
| DecoderNB.forward:208 | `F.softplus(...) + eps` | âœ… è‰¯å¥½ |
| nb_log_likelihood:311-312 | `torch.log(... + eps)` | âš ï¸ éœ€æ”¹è¿›ï¼ˆè§é—®é¢˜2ï¼‰ |
| sample_z:243 | `torch.exp(0.5*logvar)` | âœ… è‰¯å¥½ï¼ˆlogvaré¿å…ç›´æ¥exp(å¤§æ•°)ï¼‰ |
| elbo_loss | æ— ç‰¹æ®Šå¤„ç† | âœ… è‰¯å¥½ï¼ˆKLå’Œlog_pxéƒ½æ˜¯ç¨³å®šçš„ï¼‰ |

### operator.py ç¨³å®šæ€§æªæ–½

| ä½ç½® | ç¨³å®šæ€§æªæ–½ | è¯„ä¼° |
|------|------------|------|
| forward:215 | bmm + squeeze | âœ… è‰¯å¥½ |
| spectral_penalty:280 | `v.norm() + eps` | âœ… è‰¯å¥½ |
| compute_operator_norm:406 | `v.norm() + eps` | âœ… è‰¯å¥½ |

**æ½œåœ¨é£é™©ç‚¹**ï¼š

1. **è°±èŒƒæ•°æƒ©ç½šå¤±æ•ˆ**ï¼šå¦‚æœA_Î¸çš„çœŸå®è°±èŒƒæ•°>1.5ï¼Œä½†ç‰¹å¾å€¼<1.05ï¼Œæƒ©ç½šä¸ä¼šè§¦å‘
2. **æ¢¯åº¦çˆ†ç‚¸/æ¶ˆå¤±**ï¼šå¦‚æœç®—å­ä¸ç¨³å®šï¼Œå¤šæ­¥åº”ç”¨å¯èƒ½å¯¼è‡´zå‘æ•£æˆ–æ”¶ç¼©
3. **è´ŸäºŒé¡¹åˆ†å¸ƒå‚æ•°æç«¯å€¼**ï¼šrâ†’0æ—¶æ¥è¿‘æ³Šæ¾åˆ†å¸ƒï¼Œrâ†’âˆæ—¶æ¥è¿‘é«˜æ–¯åˆ†å¸ƒ

---

## å†…å­˜æ•ˆç‡åˆ†æ

### âœ… ä¼˜ç§€å®è·µ

1. **ä½¿ç”¨einsumé¿å…expand** (operator.py:196, 207)
   ```python
   # é¿å…åˆ›å»º (B, K, d, d) çš„ä¸­é—´å¼ é‡
   A_res = torch.einsum('bk,kij->bij', alpha, self.B)
   ```
   - å†…å­˜èŠ‚çœï¼šå¯¹äºB=128, K=10, d=32ï¼š
     - expandæ–¹å¼ï¼š128Ã—10Ã—32Ã—32Ã—4B = 5.24 MB
     - einsumæ–¹å¼ï¼š128Ã—32Ã—32Ã—4B = 0.52 MB
     - èŠ‚çœï¼š**10å€**

2. **detachç”¨äºåˆ‡æ–­ä¸å¿…è¦çš„æ¢¯åº¦** (nb_vae.py:464)
   ```python
   return loss, z.detach()
   ```
   - é¿å…ä¸‹æ¸¸è®¡ç®—å›¾ä¿ç•™VAEçš„æ¢¯åº¦

### âš ï¸ å¯ä¼˜åŒ–ç‚¹

1. **spectral_penaltyçš„forå¾ªç¯** (operator.py:270-308)
   - å½“å‰ï¼šé¡ºåºè®¡ç®—n_tissues + Kä¸ªçŸ©é˜µ
   - å¯ä¼˜åŒ–ï¼šæ‰¹é‡å¤„ç†ï¼ˆä½†ä¼˜å…ˆçº§ä¸é«˜ï¼Œå› ä¸ºn_tissueså’ŒKé€šå¸¸è¾ƒå°ï¼‰

---

## è¾¹ç•Œæ¡ä»¶å’Œç‰¹æ®Šæƒ…å†µ

### âœ… å·²å¤„ç†çš„è¾¹ç•Œæ¡ä»¶

1. **ç©ºbatch**ï¼šæ‰€æœ‰æ–¹æ³•æ”¯æŒB=0ï¼ˆè™½ç„¶ä¸å¸¸è§ï¼‰
2. **å•æ ·æœ¬**ï¼šæ‰€æœ‰æ–¹æ³•æ”¯æŒB=1
3. **râ†’0**ï¼šlog_dispersionå¯ä»¥æ˜¯è´Ÿæ— ç©·ï¼ˆexp(-âˆ)=0ï¼‰ï¼Œä½†å®é™…å—é™äºæµ®ç‚¹ç²¾åº¦
4. **Î¼=0**ï¼šé€šè¿‡softplus+epsä¿è¯Î¼>eps

### âš ï¸ æœªå……åˆ†å¤„ç†çš„è¾¹ç•Œæ¡ä»¶

1. **cond_vecå…¨é›¶**ï¼šalpha_mlpå’Œbeta_mlpçš„è¾“å‡ºå¯èƒ½æ¥è¿‘0ï¼Œä½†æ²¡æœ‰æ˜ç¡®ä¿è¯
2. **tissue_idxè¶Šç•Œ**ï¼šæ²¡æœ‰æ˜¾å¼æ£€æŸ¥ï¼ˆä¾èµ–PyTorchçš„ç´¢å¼•æ£€æŸ¥ï¼‰
3. **è°±èŒƒæ•°è®¡ç®—åœ¨A=0æ—¶**ï¼špower iterationå¯èƒ½ä¸æ”¶æ•›ï¼ˆä½†å®é™…ä¸å¤ªå¯èƒ½ï¼‰

---

## æ¢¯åº¦æµåŠ¨åˆ†æ

### âœ… æ¢¯åº¦è·¯å¾„æ­£ç¡®

1. **VAEçš„æ¢¯åº¦**ï¼š
   ```
   loss â† ELBO â† log_px â† DecoderNB â† z â† sample_z (é‡å‚æ•°åŒ–) â† Encoder
   loss â† ELBO â† KL â† Encoder (mu_z, logvar_z)
   ```
   - âœ… é‡å‚æ•°åŒ–æŠ€å·§æ­£ç¡®å®ç°
   - âœ… KLæ•£åº¦å¯¹muå’Œlogvaréƒ½æœ‰æ¢¯åº¦

2. **Operatorçš„æ¢¯åº¦**ï¼š
   ```
   z_out â† bmm(A_theta, z) + b_theta
         â† A_theta = A0 + einsum(alpha, B)
         â† alpha = alpha_mlp(cond_vec)
   ```
   - âœ… einsumå¯å¾®
   - âœ… alpha_mlpå¯å¾®
   - âœ… A0_tissue, Bæ˜¯å¯å­¦ä¹ å‚æ•°

3. **è°±èŒƒæ•°æƒ©ç½šçš„æ¢¯åº¦**ï¼š
   ```
   penalty â† (spec - max_allowed)Â²
           â† spec = v @ (A @ v)
           â† A (vå·²detach)
   ```
   - âœ… vçš„detachæ­£ç¡®ï¼ˆvæ˜¯é€šè¿‡power iterationè¿­ä»£å¾—åˆ°çš„ï¼Œä¸éœ€è¦å¯¹è¿­ä»£è¿‡ç¨‹æ±‚å¯¼ï¼‰
   - âœ… specå¯¹Aæœ‰æ¢¯åº¦

### âš ï¸ æ½œåœ¨æ¢¯åº¦é—®é¢˜

1. **è°±èŒƒæ•°æ¢¯åº¦åœ¨ä¸´ç•Œç‚¹ä¸è¿ç»­**ï¼š
   - å½“specç•¥å°äºmax_allowedæ—¶ï¼Œæ¢¯åº¦=0
   - å½“specç•¥å¤§äºmax_allowedæ—¶ï¼Œæ¢¯åº¦â‰ 0
   - å»ºè®®ï¼šä½¿ç”¨soft thresholdï¼ˆå¦‚smooth ReLUï¼‰

---

## ä¿®å¤ä¼˜å…ˆçº§æ€»ç»“

| ä¼˜å…ˆçº§ | é—®é¢˜ç¼–å· | é—®é¢˜æè¿° | å»ºè®®ä¿®å¤æ—¶é—´ |
|--------|----------|----------|--------------|
| ğŸ”´ é«˜ | é—®é¢˜1 | è°±èŒƒæ•°è®¡ç®—æ–¹æ³•é”™è¯¯ | ç«‹å³ä¿®å¤ |
| ğŸŸ¡ ä¸­ | é—®é¢˜2 | nb_log_likelihoodæ•°å€¼ç¨³å®šæ€§ | 1-2å¤©å†… |
| ğŸŸ¡ ä¸­ | é—®é¢˜3 | å¼ é‡æ¯”è¾ƒé€»è¾‘ | 1-2å¤©å†… |
| ğŸŸ¢ ä½ | é—®é¢˜4 | compute_operator_normæœªå‘é‡åŒ– | å¯é€‰ä¼˜åŒ– |
| ğŸŸ¢ ä½ | é—®é¢˜5 | å˜é‡å‘½åæ··æ·† | å¯é€‰ä¼˜åŒ– |

---

## å»ºè®®çš„ä¿®å¤æ–¹æ¡ˆ

### ä¿®å¤é—®é¢˜1ï¼šè°±èŒƒæ•°è®¡ç®—

**é€‰é¡¹A**ï¼ˆæ¨èï¼‰ï¼šä½¿ç”¨A^T Açš„Power Iteration

```python
def spectral_penalty(self, max_allowed=1.05, n_iterations=5):
    penalty = torch.tensor(0.0, device=self.A0_tissue.device)

    # å¯¹A_t^(0)è®¡ç®—è°±èŒƒæ•°
    for t in range(self.n_tissues):
        A0 = self.A0_tissue[t]  # (d, d)

        # Power iteration for A^T A
        with torch.no_grad():
            v = torch.randn(A0.size(0), device=A0.device)
            for _ in range(n_iterations):
                v = A0.T @ (A0 @ v)  # (A^T A) v
                v = v / (v.norm() + _NUM_CFG.eps_division)

        # è°±èŒƒæ•° = sqrt(v^T A^T A v)
        v_detached = v.detach()
        ATA_v = A0.T @ (A0 @ v_detached)
        spec = torch.sqrt((v_detached @ ATA_v).abs() + _NUM_CFG.eps_log)

        # Soft penalty
        excess = spec - max_allowed
        penalty = penalty + F.relu(excess) ** 2

    # å¯¹B_kè®¡ç®—è°±èŒƒæ•°ï¼ˆåŒæ ·çš„é€»è¾‘ï¼‰
    for k in range(self.K):
        Bk = self.B[k]
        with torch.no_grad():
            v = torch.randn(Bk.size(0), device=Bk.device)
            for _ in range(n_iterations):
                v = Bk.T @ (Bk @ v)
                v = v / (v.norm() + _NUM_CFG.eps_division)

        v_detached = v.detach()
        BTB_v = Bk.T @ (Bk @ v_detached)
        spec = torch.sqrt((v_detached @ BTB_v).abs() + _NUM_CFG.eps_log)

        excess = spec - max_allowed
        penalty = penalty + F.relu(excess) ** 2

    return penalty
```

**é€‰é¡¹B**ï¼ˆç®€åŒ–ç‰ˆï¼‰ï¼šä½¿ç”¨FrobeniusèŒƒæ•°ä¸Šç•Œ

```python
# åˆ©ç”¨ ||A||_2 â‰¤ ||A||_F
def spectral_penalty(self, max_allowed=1.05):
    penalty = torch.tensor(0.0, device=self.A0_tissue.device)

    # FrobeniusèŒƒæ•°ï¼š||A||_F = sqrt(Î£áµ¢â±¼ AÂ²áµ¢â±¼)
    for t in range(self.n_tissues):
        frob_norm = torch.norm(self.A0_tissue[t], p='fro')
        excess = frob_norm - max_allowed
        penalty = penalty + F.relu(excess) ** 2

    for k in range(self.K):
        frob_norm = torch.norm(self.B[k], p='fro')
        excess = frob_norm - max_allowed
        penalty = penalty + F.relu(excess) ** 2

    return penalty
```

**æ¨è**ï¼šé€‰é¡¹Aï¼ˆæ›´å‡†ç¡®ï¼‰ï¼Œæˆ–åœ¨æ€§èƒ½å…³é”®æ—¶ä½¿ç”¨é€‰é¡¹Bã€‚

---

### ä¿®å¤é—®é¢˜2ï¼šnb_log_likelihoodæ•°å€¼ç¨³å®šæ€§

```python
def nb_log_likelihood(x, mu, r, eps=None):
    if eps is None:
        eps = _NUM_CFG.eps_log

    x = x.float()

    # log Î“é¡¹ï¼ˆä¸å˜ï¼‰
    log_coef = (
        torch.lgamma(x + r)
        - torch.lgamma(r)
        - torch.lgamma(x + 1.0)
    )

    # æ”¹è¿›ï¼šä½¿ç”¨logçš„å‡æ³•æ€§è´¨
    log_r = torch.log(r + eps)
    log_mu = torch.log(mu + eps)
    log_r_plus_mu = torch.log(r + mu + eps)

    log_r_over_r_plus_mu = log_r - log_r_plus_mu
    log_mu_over_r_plus_mu = log_mu - log_r_plus_mu

    log_p = (
        log_coef
        + r * log_r_over_r_plus_mu
        + x * log_mu_over_r_plus_mu
    )

    return log_p.sum(dim=-1)
```

---

### ä¿®å¤é—®é¢˜3ï¼šå¼ é‡æ¯”è¾ƒ

```python
def spectral_penalty(self, max_allowed=1.05, n_iterations=5):
    penalty = torch.tensor(0.0, device=self.A0_tissue.device)

    for t in range(self.n_tissues):
        A0 = self.A0_tissue[t]
        # ... power iteration ...
        spec = (v_detached @ (A0 @ v_detached)).abs()

        # ä½¿ç”¨ReLUæ›¿ä»£ifåˆ¤æ–­
        excess = spec - max_allowed
        penalty = penalty + F.relu(excess) ** 2

    # å¯¹B_kåŒæ ·å¤„ç†
    # ...

    return penalty
```

---

## æµ‹è¯•å»ºè®®

ä¿®å¤åï¼Œå»ºè®®æ·»åŠ ä»¥ä¸‹æµ‹è¯•ï¼š

```python
def test_spectral_norm_computation():
    """æµ‹è¯•è°±èŒƒæ•°è®¡ç®—çš„æ­£ç¡®æ€§"""
    # æ„é€ å·²çŸ¥è°±èŒƒæ•°çš„çŸ©é˜µ
    A = torch.diag(torch.tensor([2.0, 1.0, 0.5]))  # è°±èŒƒæ•° = 2.0

    model = OperatorModel(latent_dim=3, n_tissues=1, n_response_bases=1, cond_dim=4)
    model.A0_tissue.data[0] = A

    # è®¡ç®—è°±èŒƒæ•°
    tissue_idx = torch.zeros(1, dtype=torch.long)
    cond_vec = torch.zeros(1, 4)
    norm = model.compute_operator_norm(tissue_idx, cond_vec, norm_type="spectral")

    assert torch.abs(norm - 2.0) < 0.1, f"Expected ~2.0, got {norm.item()}"

def test_nb_log_likelihood_stability():
    """æµ‹è¯•è´ŸäºŒé¡¹å¯¹æ•°ä¼¼ç„¶åœ¨æç«¯æƒ…å†µä¸‹çš„ç¨³å®šæ€§"""
    # æå°çš„muå’Œr
    x = torch.tensor([[1.0]])
    mu = torch.tensor([[1e-10]])
    r = torch.tensor([[1e-10]])

    log_p = nb_log_likelihood(x, mu, r)

    assert torch.isfinite(log_p).all(), "Log likelihood should be finite"
    assert not torch.isnan(log_p).any(), "Log likelihood contains NaN"
```

---

## æ€»ä½“è¯„ä¼°

### ä¼˜ç‚¹

1. âœ… **æ•°å­¦å®ç°å¿ å®äºmodel.md**ï¼šå…¬å¼å¯¹åº”å…³ç³»æ¸…æ™°ï¼Œæ³¨é‡Šè¯¦ç»†
2. âœ… **ç»´åº¦å¤„ç†æ­£ç¡®**ï¼šæ‰€æœ‰å¼ é‡æ“ä½œç»´åº¦åŒ¹é…ï¼Œæ”¯æŒæ‰¹å¤„ç†
3. âœ… **å‘é‡åŒ–è‰¯å¥½**ï¼šå¤§éƒ¨åˆ†æ“ä½œä½¿ç”¨einsum/bmmï¼Œé¿å…å¾ªç¯
4. âœ… **æ³¨é‡Šå®Œæ•´**ï¼šä¸­æ–‡docstringè¯¦ç»†ï¼Œç¬¦åˆé¡¹ç›®è§„èŒƒ
5. âœ… **ä»£ç ç»“æ„æ¸…æ™°**ï¼šæ¨¡å—åŒ–è®¾è®¡ï¼ŒèŒè´£åˆ†ç¦»æ˜ç¡®

### éœ€è¦æ”¹è¿›

1. âŒ **è°±èŒƒæ•°è®¡ç®—é”™è¯¯**ï¼šå½±å“æ¨¡å‹ç¨³å®šæ€§ä¿è¯
2. âš ï¸ **éƒ¨åˆ†æ•°å€¼ç¨³å®šæ€§ä¸è¶³**ï¼šæç«¯æƒ…å†µä¸‹å¯èƒ½å‡ºé—®é¢˜
3. âš ï¸ **å¼ é‡æ¯”è¾ƒä¸è§„èŒƒ**ï¼šå½±å“TorchScriptå…¼å®¹æ€§

### æœ€ç»ˆå»ºè®®

**é€šè¿‡æ¡ä»¶**ï¼šä¿®å¤é—®é¢˜1å’Œé—®é¢˜2åé€šè¿‡

**ç†ç”±**ï¼š
- é—®é¢˜1å½±å“æ¨¡å‹çš„æ ¸å¿ƒç¨³å®šæ€§ä¿è¯ï¼Œå¿…é¡»ä¿®å¤
- é—®é¢˜2åœ¨å®é™…æ•°æ®ä¸­å¯èƒ½è§¦å‘ï¼Œå»ºè®®ä¿®å¤
- é—®é¢˜3ã€4ã€5ä¸ºä»£ç è´¨é‡é—®é¢˜ï¼Œå¯åœ¨åç»­è¿­ä»£ä¸­ä¼˜åŒ–

**ä¿®å¤åé¢„æœŸè¯„åˆ†**ï¼š95/100

---

## é™„å½•ï¼šä»£ç è´¨é‡è¯„åˆ†ç»†åˆ™

| è¯„åˆ†ç»´åº¦ | åˆ†æ•° | è¯´æ˜ |
|----------|------|------|
| **æ•°å­¦æ­£ç¡®æ€§** | 16/20 | -2åˆ†ï¼ˆè°±èŒƒæ•°é”™è¯¯ï¼‰ï¼Œ-2åˆ†ï¼ˆæ•°å€¼ç¨³å®šæ€§ï¼‰ |
| **ç»´åº¦ä¸€è‡´æ€§** | 20/20 | æ‰€æœ‰ç»´åº¦æ­£ç¡® |
| **ä»£ç å¯è¯»æ€§** | 18/20 | -1åˆ†ï¼ˆå˜é‡å‘½åï¼‰ï¼Œ-1åˆ†ï¼ˆéƒ¨åˆ†é€»è¾‘å¯ç®€åŒ–ï¼‰ |
| **æ€§èƒ½ä¼˜åŒ–** | 18/20 | -2åˆ†ï¼ˆcompute_operator_normæœªå‘é‡åŒ–ï¼‰ |
| **æ•°å€¼ç¨³å®šæ€§** | 15/20 | -3åˆ†ï¼ˆepsilonä½ç½®ï¼‰ï¼Œ-2åˆ†ï¼ˆæç«¯æƒ…å†µæœªå……åˆ†æµ‹è¯•ï¼‰ |
| **æ–‡æ¡£å®Œæ•´æ€§** | 20/20 | docstringå’Œæ³¨é‡Šä¼˜ç§€ |
| **æµ‹è¯•è¦†ç›–** | 0/0 | ï¼ˆæœ¬æ¬¡ä¸è¯„åˆ†ï¼Œéœ€å•ç‹¬å®¡æŸ¥æµ‹è¯•æ–‡ä»¶ï¼‰ |

**æ€»åˆ†**ï¼š107/120 â†’ å½’ä¸€åŒ–åˆ°100åˆ†åˆ¶ï¼š**89/100**

è€ƒè™‘é—®é¢˜ä¸¥é‡æ€§åŠ æƒï¼š**82/100**ï¼ˆè°±èŒƒæ•°é”™è¯¯å½±å“è¾ƒå¤§ï¼‰

---

**ç”Ÿæˆæ—¶é—´**ï¼š2025-11-18
**å®¡æŸ¥è€…**ï¼šClaude Code
**ä¸‹æ¬¡å®¡æŸ¥å»ºè®®**ï¼šä¿®å¤é—®é¢˜1å’Œé—®é¢˜2åé‡æ–°å®¡æŸ¥
